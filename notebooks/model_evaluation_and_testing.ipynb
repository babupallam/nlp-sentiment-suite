{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-27T00:17:40.780524Z",
     "start_time": "2024-11-27T00:17:35.770307Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from transformers import TFBertForSequenceClassification, BertTokenizer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "data_path = \"./data/\"  # Change this to your dataset directory in Colab\n",
    "model_save_path = \"./models/\"\n",
    "test_file = os.path.join(data_path, \"test_data.csv\")\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_model\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TFBertForSequenceClassification, BertTokenizer\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'transformers'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Load test data\n",
    "def load_test_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "test_df = load_test_data(test_file)\n",
    "X_test = test_df['clean_text']\n",
    "y_test = test_df['category']\n",
    "\n",
    "# General evaluation function\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Function to evaluate a model using standard metrics.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"\\n{model_name} Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n"
   ],
   "id": "ad7282f00adc4f47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# **Section 1: Baseline Models**\n",
    "print(\"Evaluating Baseline Models...\")\n",
    "def evaluate_baseline_models(X_test, y_test):\n",
    "    \"\"\"\n",
    "    Function to load and evaluate baseline models: Logistic Regression, Naive Bayes, and SVM.\n",
    "    \"\"\"\n",
    "    baseline_models = [\"Logistic_Regression.pkl\", \"Naive_Bayes.pkl\", \"SVM.pkl\"]\n",
    "    vectorizer = joblib.load(os.path.join(model_save_path, \"tfidf_vectorizer.pkl\"))\n",
    "\n",
    "    # Transform test data\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    for model_file in baseline_models:\n",
    "        model = joblib.load(os.path.join(model_save_path, model_file))\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "        evaluate_model(y_test, y_pred, model_file.replace(\".pkl\", \"\"))\n",
    "\n",
    "evaluate_baseline_models(X_test, y_test)\n",
    "\n"
   ],
   "id": "f5931efcb7d89878"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# **Section 2: LSTM Model**\n",
    "print(\"\\nEvaluating LSTM Model...\")\n",
    "def evaluate_lstm_model(X_test, y_test):\n",
    "    \"\"\"\n",
    "    Function to load and evaluate the LSTM model.\n",
    "    \"\"\"\n",
    "    lstm_model = load_model(os.path.join(model_save_path, \"lstm_model.h5\"))\n",
    "    tokenizer = joblib.load(os.path.join(model_save_path, \"tokenizer.pkl\"))\n",
    "    label_encoder = joblib.load(os.path.join(model_save_path, \"label_encoder.pkl\"))\n",
    "\n",
    "    # Preprocess test data\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "    X_test_padded = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=100)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "    # Predict\n",
    "    y_probs = lstm_model.predict(X_test_padded)\n",
    "    y_pred = np.argmax(y_probs, axis=1)\n",
    "\n",
    "    evaluate_model(y_test_encoded, y_pred, \"LSTM Model\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test_encoded, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix for LSTM Model\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()\n",
    "\n",
    "evaluate_lstm_model(X_test, y_test)\n",
    "\n"
   ],
   "id": "3e43ff641476ee4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# **Section 3: BERT Model**\n",
    "print(\"\\nEvaluating BERT Model...\")\n",
    "def evaluate_bert_model(X_test, y_test):\n",
    "    \"\"\"\n",
    "    Function to load and evaluate the BERT model.\n",
    "    \"\"\"\n",
    "    bert_model = TFBertForSequenceClassification.from_pretrained(os.path.join(model_save_path, \"bert_model\"))\n",
    "    tokenizer = BertTokenizer.from_pretrained(os.path.join(model_save_path, \"bert_tokenizer\"))\n",
    "    label_mapping = joblib.load(os.path.join(model_save_path, \"bert_label_mapping.pkl\"))\n",
    "\n",
    "    # Preprocess test data\n",
    "    X_test_enc = tokenizer(\n",
    "        list(X_test),\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    y_test_encoded = y_test.map(label_mapping).values\n",
    "\n",
    "    # Predict\n",
    "    y_probs = bert_model.predict({\"input_ids\": X_test_enc[\"input_ids\"], \"attention_mask\": X_test_enc[\"attention_mask\"]}).logits\n",
    "    y_pred = np.argmax(y_probs, axis=1)\n",
    "\n",
    "    evaluate_model(y_test_encoded, y_pred, \"BERT Model\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test_encoded, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix for BERT Model\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()\n",
    "\n",
    "evaluate_bert_model(X_test, y_test)\n"
   ],
   "id": "8377529d5db36fc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a7a30d4112211aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a0fb323a7a32a432"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ffc1cc7aa86ebb53"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
