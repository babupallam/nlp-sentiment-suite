{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-26T23:26:42.821657Z",
     "start_time": "2024-11-26T23:26:35.882625Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Define file paths for data and model saving\n",
    "data_path = \"../data/\"\n",
    "train_file = data_path + \"train_data.csv\"\n",
    "val_file = data_path + \"val_data.csv\"\n",
    "model_save_path = \"../models/\"\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T23:56:16.835379Z",
     "start_time": "2024-11-26T23:56:11.404596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load training and validation data\n",
    "def load_data(train_path, val_path):\n",
    "    \"\"\"\n",
    "    Load training and validation data from CSV files with debug statements.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load training and validation CSV files\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        val_df = pd.read_csv(val_path)\n",
    "\n",
    "        # Debug: Print shapes of dataframes\n",
    "        print(f\"[DEBUG] Training data loaded successfully with shape: {train_df.shape}\")\n",
    "        print(f\"[DEBUG] Validation data loaded successfully with shape: {val_df.shape}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"[ERROR] File not found: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] An unexpected error occurred while loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "    return train_df, val_df\n",
    "\n",
    "\n",
    "# Load the data into DataFrames\n",
    "train_df, val_df = load_data(train_file, val_file)\n",
    "\n",
    "# Extract text and labels from data\n",
    "try:\n",
    "    # Handle missing or non-string values in 'clean_text' by filling with empty strings\n",
    "    train_df['clean_text'] = train_df['clean_text'].fillna('').astype(str)\n",
    "    val_df['clean_text'] = val_df['clean_text'].fillna('').astype(str)\n",
    "\n",
    "    X_train, y_train = train_df['clean_text'], train_df['category']\n",
    "    X_val, y_val = val_df['clean_text'], val_df['category']\n",
    "\n",
    "    # Debug: Print shapes of text and label data\n",
    "    print(f\"[DEBUG] X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"[DEBUG] X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "except KeyError as e:\n",
    "    print(f\"[ERROR] Key error: {e}. Please check if the expected columns exist.\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "def prepare_text_sequences(X_train, X_val, max_words=10000, max_len=100):\n",
    "    \"\"\"\n",
    "    Tokenize and pad text sequences for deep learning models with debug statements.\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    # Convert text to sequences\n",
    "    train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "    # Debug: Print an example of tokenized sequence\n",
    "    print(f\"[DEBUG] Example of tokenized training sequence: {train_sequences[:1]}\")\n",
    "\n",
    "    # Pad sequences to ensure equal length\n",
    "    train_padded = pad_sequences(train_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "    val_padded = pad_sequences(val_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "    # Debug: Print shapes of padded sequences\n",
    "    print(f\"[DEBUG] Padded training sequence shape: {train_padded.shape}\")\n",
    "    print(f\"[DEBUG] Padded validation sequence shape: {val_padded.shape}\")\n",
    "\n",
    "    return train_padded, val_padded, tokenizer\n",
    "\n",
    "\n",
    "# Prepare sequences for training and validation sets\n",
    "X_train_padded, X_val_padded, tokenizer = prepare_text_sequences(X_train, X_val)\n",
    "\n",
    "# Convert labels to integer type to avoid float issues\n",
    "try:\n",
    "    y_train = y_train.astype(int)\n",
    "    y_val = y_val.astype(int)\n",
    "    # Debug: Print unique values of labels to confirm correct conversion\n",
    "    print(f\"[DEBUG] Labels converted to integer type. y_train unique values: {y_train.unique()}\")\n",
    "except ValueError as e:\n",
    "    print(f\"[ERROR] Value error while converting labels to integers: {e}\")\n",
    "    raise\n",
    "\n"
   ],
   "id": "af8433c5047c86b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Training data loaded successfully with shape: (104302, 6)\n",
      "[DEBUG] Validation data loaded successfully with shape: (26076, 6)\n",
      "[DEBUG] X_train shape: (104302,), y_train shape: (104302,)\n",
      "[DEBUG] X_val shape: (26076,), y_val shape: (26076,)\n",
      "[DEBUG] Example of tokenized training sequence: [[1, 23, 202, 682, 2, 4, 92, 313, 346, 187, 9, 684, 3, 183, 4735, 1313]]\n",
      "[DEBUG] Padded training sequence shape: (104302, 100)\n",
      "[DEBUG] Padded validation sequence shape: (26076, 100)\n",
      "[DEBUG] Labels converted to integer type. y_train unique values: [ 0  1 -1]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T23:56:28.003172Z",
     "start_time": "2024-11-26T23:56:25.906218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# One-hot encode labels\n",
    "def one_hot_encode_labels(y_train, y_val):\n",
    "    \"\"\"\n",
    "    One-hot encode labels for multi-class classification with debug statements.\n",
    "    \"\"\"\n",
    "    encoder = LabelBinarizer()\n",
    "\n",
    "    try:\n",
    "        y_train_encoded = encoder.fit_transform(y_train)\n",
    "        y_val_encoded = encoder.transform(y_val)\n",
    "        # Debug: Print an example of encoded label and shapes of encoded arrays\n",
    "        print(f\"[DEBUG] Example of one-hot encoded training label: {y_train_encoded[:1]}\")\n",
    "        print(f\"[DEBUG] One-hot encoded training labels shape: {y_train_encoded.shape}\")\n",
    "        print(f\"[DEBUG] One-hot encoded validation labels shape: {y_val_encoded.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Error occurred during one-hot encoding: {e}\")\n",
    "        raise\n",
    "\n",
    "    return y_train_encoded, y_val_encoded, encoder\n",
    "\n",
    "\n",
    "# Apply one-hot encoding to labels\n",
    "y_train_encoded, y_val_encoded, label_encoder = one_hot_encode_labels(y_train, y_val)\n",
    "\n",
    "# Save the tokenizer and label encoder for future use\n",
    "try:\n",
    "    joblib.dump(tokenizer, os.path.join(model_save_path, \"tokenizer.pkl\"))\n",
    "    joblib.dump(label_encoder, os.path.join(model_save_path, \"label_encoder.pkl\"))\n",
    "    print(\"[DEBUG] Tokenizer and label encoder saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Error saving tokenizer or label encoder: {e}\")\n",
    "    raise\n"
   ],
   "id": "97564e4d049dc945",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Example of one-hot encoded training label: [[0 1 0]]\n",
      "[DEBUG] One-hot encoded training labels shape: (104302, 3)\n",
      "[DEBUG] One-hot encoded validation labels shape: (26076, 3)\n",
      "[DEBUG] Tokenizer and label encoder saved successfully.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T23:56:34.036268Z",
     "start_time": "2024-11-26T23:56:33.984094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Define a custom PyTorch Dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = torch.tensor(sequences, dtype=torch.long)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "# Create Dataset objects for training and validation\n",
    "train_dataset = TextDataset(X_train_padded, y_train_encoded)\n",
    "val_dataset = TextDataset(X_val_padded, y_val_encoded)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n"
   ],
   "id": "5b9969bc42241a1",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T23:56:41.572507Z",
     "start_time": "2024-11-26T23:56:41.469535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Define the LSTM model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=128, lstm_units=64, output_dim=3):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, lstm_units, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(lstm_units * 2, 32)  # Bidirectional LSTM output is doubled\n",
    "        self.fc2 = nn.Linear(32, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        lstm_out = self.dropout(lstm_out[:, -1, :])  # Take output of last time step\n",
    "        fc1_out = torch.relu(self.fc1(lstm_out))\n",
    "        out = self.fc2(fc1_out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "lstm_model = LSTMClassifier(input_dim=vocab_size)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "\n"
   ],
   "id": "f2ddb3b4d3ecb9c6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:16:18.456581Z",
     "start_time": "2024-11-26T23:56:48.343103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for sequences, labels in train_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels.argmax(1))\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Debug: Print loss for each epoch\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "# Train the LSTM model\n",
    "train_model(lstm_model, train_loader, criterion, optimizer)\n"
   ],
   "id": "a411a6f50ac8f5ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 1.0607\n",
      "Epoch 2/5, Loss: 1.0601\n",
      "Epoch 3/5, Loss: 1.0597\n",
      "Epoch 4/5, Loss: 1.0597\n",
      "Epoch 5/5, Loss: 1.0596\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T00:16:28.536622Z",
     "start_time": "2024-11-27T00:16:18.513559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Import necessary metrics libraries\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in val_loader:\n",
    "            outputs = model(sequences)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())  # Ensure preds are moved to CPU\n",
    "            all_labels.extend(labels.argmax(1).cpu().numpy())  # Ensure labels are moved to CPU\n",
    "\n",
    "    # Convert to NumPy arrays for compatibility with sklearn metrics\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Debug information to understand prediction counts\n",
    "    print(f\"[DEBUG] Number of predicted samples: {len(all_preds)}\")\n",
    "    print(f\"[DEBUG] Number of actual samples: {len(all_labels)}\")\n",
    "    unique_labels = np.unique(all_labels)\n",
    "    print(f\"[DEBUG] Unique labels in ground truth: {unique_labels}\")\n",
    "\n",
    "    # Calculate evaluation metrics with zero_division handling\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"\\nLSTM Model Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "\n",
    "# Run evaluation on validation data\n",
    "evaluate_model(lstm_model, val_loader)\n",
    "\n",
    "# Save the model\n",
    "torch.save(lstm_model.state_dict(), os.path.join(model_save_path, \"lstm_model.pth\"))\n",
    "print(\"LSTM model saved.\")\n"
   ],
   "id": "9017e0c721475a21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Number of predicted samples: 26076\n",
      "[DEBUG] Number of actual samples: 26076\n",
      "[DEBUG] Unique labels in ground truth: [0 1 2]\n",
      "\n",
      "LSTM Model Evaluation Metrics:\n",
      "Accuracy: 0.4433\n",
      "F1-score: 0.2723\n",
      "Precision: 0.7532\n",
      "Recall: 0.4433\n",
      "LSTM model saved.\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
